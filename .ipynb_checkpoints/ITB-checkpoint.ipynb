{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Introspective Thought Building (ITB) for LIDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introspective thought building (ITB) takes simple cognitive tasks and analyzes them into parts that can be implemented in a LIDA cognitive cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITB is currently being developed in the context of puzzle solving. A puzzle is defined here as an environmental object with a simple, perceivable state that an agent can manipulate in a predictable way towards a specific goal state. Examples include a jigsaw puzzle, a crossword puzzle, and Rubik's cube.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Why study puzzle solving? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humans solve puzzles for fun, but computers are much better at it as far as performance goes. For many puzzles, they can calculate all the possible outcomes of all the possible actions and search the state space for solutions and paths to get to them. They can then evaluate all the paths according to some metric and then find the optimal path according to that metric. When the state space is too large for this to work, there are numerous approaches, such as variational approximation, sampling methods, and many others, that can make good headway even in the face of a combinatorial explosion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puzzle solving is easy to model with the LIDA cognitive cycle. To see why, let's unpack the above definition of a puzzle. At any given moment in time, the puzzle has a current state that can be perceived by a puzzle solving agent. The agent meets the criteria for an autonomous agent, and wants to answer the question, \"What do I do next?\" In order to decide upon its next action, the agent perceives the puzzle's current state and selects an action to modify it. That action changes the puzzle's state, and the cycle begins again.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, so what indeed. Puzzles are simple to model in LIDA, but are they useful for anything? It's hard to be certain, but at present it seems that building puzzle-solving agents using LIDA may be helpful in at least one of two ways:\n",
    "1. By creating LIDA agents that solve simple puzzles, we may learn useful things about how minds work--especially with regard to multicyclic cognition, a topic of general importance for LIDA research.\n",
    "2. By stretching the definition of a puzzle, we may find the things learned in 1. can be applied to the development of more complex kinds of solving behaviors, such as medical diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##How ITB works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITB uses introspection in the context of the LIDA Model. Introspection was an important methodology for psychology in the 19th century. However, at that time, introspectionists had no empirical means with which to validate their theories about the mind. When behaviorism made its debut in the early 20th century, it pretty much put introspectionism out of business. However, today there are many new lines of evidence that can be applied to the question of what happens between sensation and behavior. We may say more about this later, but for now, we will say that much of this evidence has been summarized in the LIDA Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phenomenal consciousness is our immediate evidence of thought. Introspection is a process by which we examine the contents of our conscious experience and try to draw inferences about how cognition functions. Introspective thought building in particular postulates  preconscious algorithms that lead to each conscious moment. In the LIDA Model, these algorithms begin in the Workspace, their sum total activity ending in the Global Workspace, when the contents of the next conscious moment will be determined. An action will result, and the cycle will begin anew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, using the LIDA Model, we can use introspection as part of a process for building an implementation of a particular cognitive cycle in the context of a specific agent's sequence of selected actions. In general, we can \"tabulate\" a cognitive process like so:\n",
    "\n",
    "<table>\n",
    "<tbody><tr>\n",
    "<th>Time</th>\n",
    "<th>Environment</th>\n",
    "<th>Conscious moment</th>\n",
    "<th>Selected action</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Now</td>\n",
    "<td>The current situation</td>\n",
    "<td>My current conscious content</td>\n",
    "<td>My next action</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Next cycle</td>\n",
    "<td>The new situation<BR/>(the result of my action)</td>\n",
    "<td>My next conscious broadcast</td>\n",
    "<td>The action after next</td>\n",
    "</tr><tr>\n",
    "<td>Cycle after next</td>\n",
    "<td>The new situation<BR/>(the result of my action)</td>\n",
    "<td>The broadcast after that</td>\n",
    "<td>(and so on)</td>\n",
    "</tr>\n",
    "</tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct observation can fill all but the \"conscious moment\" column, which requires introspection. ITB attempts to fill in all gaps between an agent's sensing of the present environment and the selection of its next action. If we can design processes for PAM, the Workspace, and the other LIDA modules for an agent that produces the same tabulation, then\n",
    "<ol type=\"A\">\n",
    "<li>If we are creating an agent to explain the cognition and behavior of a biological mind, such an agent represents one hypothesis (or set of hypotheses) about how the biological mind accomplishes the task under consideration.</li><li>\n",
    "If we are creating an agent for a technological purpose, we can evaluate the performance of the agent and see if it meets our design criteria. Such an agent may employ non-biological mechanisms in the context of LIDA's general cyclic architecture, since its purpose is not to explain mind but to utilize LIDA's cycle. An interesting question is whether an agent that \"thinks\" like a human will be able to solve problems that current computational approaches struggle with.</li></ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
